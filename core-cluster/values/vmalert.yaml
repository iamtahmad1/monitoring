# VMAlert - VictoriaMetrics Alerting

# Server configuration
server:
  enabled: true
  
  # Resources
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 256Mi
  
  # Datasource - Victoria Metrics
  datasource:
    url: http://victoria-metrics-single-server.monitoring.svc:8428
  
  # Remote write for recording rules
  remote:
    write:
      url: http://victoria-metrics-single-server.monitoring.svc:8428/api/v1/write
    read:
      url: http://victoria-metrics-single-server.monitoring.svc:8428
  
  # Notifier - AlertManager compatible endpoint
  notifier:
    alertmanager:
      url: http://vmalertmanager.monitoring.svc:9093
  
  # Extra args
  extraArgs:
    envflag.enable: "true"
    envflag.prefix: VM_
    loggerFormat: json
  
  # Ingress
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - name: vmalert.dev.cluster.lan
        path: /
  
  # Config with alerting rules
  config:
    alerts:
      groups:
        - name: kubernetes-alerts
          rules:
            - alert: KubernetesPodNotReady
              expr: kube_pod_status_phase{phase=~"Pending|Unknown|Failed"} > 0
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "Pod {{ $labels.namespace }}/{{ $labels.pod }} is not ready"
                description: "Pod has been in non-ready state for more than 5 minutes."
            
            - alert: KubernetesNodeNotReady
              expr: kube_node_status_condition{condition="Ready",status="true"} == 0
              for: 5m
              labels:
                severity: critical
              annotations:
                summary: "Node {{ $labels.node }} is not ready"
                description: "Node has been in non-ready state for more than 5 minutes."
            
            - alert: HighMemoryUsage
              expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "High memory usage on {{ $labels.instance }}"
                description: "Memory usage is above 85%"
            
            - alert: HighCPUUsage
              expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 85
              for: 5m
              labels:
                severity: warning
              annotations:
                summary: "High CPU usage on {{ $labels.instance }}"
                description: "CPU usage is above 85%"
        
        - name: victoria-metrics-alerts
          rules:
            - alert: VictoriaMetricsDown
              expr: up{job=~".*victoria.*"} == 0
              for: 1m
              labels:
                severity: critical
              annotations:
                summary: "Victoria Metrics is down"
                description: "Victoria Metrics has been down for more than 1 minute."

# AlertManager (bundled with vmalert chart)
alertmanager:
  enabled: true
  
  # Resources
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 256Mi
  
  # Persistence
  persistentVolume:
    enabled: true
    size: 2Gi
  
  # Ingress
  ingress:
    enabled: true
    ingressClassName: nginx
    hosts:
      - name: alertmanager.dev.cluster.lan
        path: /
  
  # AlertManager config
  config:
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'namespace', 'severity']
      group_wait: 30s
      group_interval: 5m
      repeat_interval: 12h
      receiver: 'default-receiver'
      routes:
        - receiver: 'critical-receiver'
          matchers:
            - severity="critical"
          continue: true
        - receiver: 'warning-receiver'
          matchers:
            - severity="warning"
    
    receivers:
      - name: 'default-receiver'
        # Configure your receivers here
        # webhook_configs:
        #   - url: 'http://alerthandler:8080/alerts'
      
      - name: 'critical-receiver'
        # Configure critical alerts receiver
      
      - name: 'warning-receiver'
        # Configure warning alerts receiver
    
    templates:
      - '/etc/alertmanager/*.tmpl'

# ServiceMonitor (disabled - requires Prometheus Operator CRDs)
serviceMonitor:
  enabled: false

